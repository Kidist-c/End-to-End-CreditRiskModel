### An End-to-End Implementation for Building, Deploying, and Automating a Credit Risk Model

#### ğŸ§© Problem Statement

- Bati Bank is partnering with a fast-growing eCommerce platform to launch a Buy-Now-Pay-Later (BNPL) service ğŸ›’ğŸ’³. To ensure responsible lending and compliance with the Basel II Capital Accord, the bank needs a data-driven credit scoring system that can assess customer risk using behavioral data.

- The key challenge is the absence of a direct default label. To address this, the project leverages Recency, Frequency, and Monetary (RFM) transaction patterns to engineer a proxy credit risk variable, enabling the estimation of a customerâ€™s likelihood of default ğŸ“Š.

###### This project aims to:

- Define a proxy variable to classify customers as low risk (good) or high risk (bad) âš–ï¸

- Select behavioral features that strongly predict credit risk ğŸ”

- Build a model that estimates risk probability (Probability of Default) ğŸ“ˆ

- Convert risk probabilities into an interpretable credit score ğŸ§®

- Recommend an optimal loan amount and repayment duration that balances risk and business objectives â³ğŸ’°

- The final solution will support transparent, compliant, and scalable credit decisions, enabling safe expansion of BNPL services while managing financial risk responsibly.

#### Credit Scoring Business Understanding.

1ï¸âƒ£ Basel II, Risk Measurement & Interpretability ğŸ¦ğŸ“Š

The Basel II Capital Accord requires banks to accurately measure and explain credit risk, as these estimates directly affect regulatory capital requirements. This makes model interpretability and strong documentation essential, allowing regulators and risk managers to understand, validate, and trust how risk predictions are produced.

2ï¸âƒ£ Proxy Default Variable & Its Risks âš ï¸

Because a direct default label is unavailable, this project defines a proxy default variable based on customer behavior (e.g., severe delinquency). While necessary for model training, proxies may not perfectly reflect true default risk, introducing bias and uncertainty. Poorly defined proxies can lead to incorrect credit decisions and regulatory concerns, so they must be carefully designed and clearly justified.

3ï¸âƒ£ Interpretable vs. Complex Models âš–ï¸

Interpretable models such as Logistic Regression with WoE offer transparency and regulatory acceptance, making them suitable for core credit decisions. More complex models like Gradient Boosting can improve predictive accuracy but are harder to explain and govern. In regulated environments, institutions must balance performance, explainability, and compliance, often using simple models as the primary decision tool and complex models as supporting or challenger models.

#### Project WOrflow

- Here is my project Folder setup
  credit-risk-model/
  â”œâ”€â”€ .github/
  â”‚ â””â”€â”€ workflows/
  â”‚ â””â”€â”€ ci.yml # Placeholder for CI/CD workflow
  â”œâ”€â”€ data/
  â”‚ â”œâ”€â”€ raw/ # Raw data (add to .gitignore)
  â”‚ â””â”€â”€ processed/ # Processed data
  â”œâ”€â”€ notebooks/
  â”‚ â””â”€â”€ eda.ipynb # Exploratory data analysis notebook
  â”œâ”€â”€ src/
  â”‚ â”œâ”€â”€ **init**.py
  â”‚ â”œâ”€â”€ data_processing.py # Feature engineering & preprocessing
  â”‚ â”œâ”€â”€ train.py # Model training script
  â”‚ â”œâ”€â”€ predict.py # Batch inference script
  â”‚ â””â”€â”€ api/
  â”‚ â”œâ”€â”€ main.py # FastAPI app for real-time inference
  â”‚ â””â”€â”€ pydantic_models.py # Pydantic models for API input/output
  â”œâ”€â”€ tests/
  â”‚ â””â”€â”€ test_data_processing.py # Unit tests
  â”œâ”€â”€ streamlit_app/
  â”‚ â””â”€â”€ app.py # Streamlit dashboard / UI
  â”œâ”€â”€ Dockerfile # Dockerfile for FastAPI service
  â”œâ”€â”€ docker-compose.yml # Compose file for API + Streamlit
  â”œâ”€â”€ requirements.txt # Python dependencies
  â”œâ”€â”€ .gitignore # Git ignore rules
  â””â”€â”€ README.md # Project documentation
  TAsk-1 : Exploratory Data Analysis (EDA)
